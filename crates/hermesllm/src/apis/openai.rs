use serde::{Deserialize, Serialize};
use serde_json::Value;
use serde_with::skip_serializing_none;
use std::collections::HashMap;

use super::ApiDefinition;

// ============================================================================
// OPENAI API ENUMERATION
// ============================================================================

/// Enum for all supported OpenAI APIs
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum OpenAIApi {
    ChatCompletions,
    // Future APIs can be added here:
    // Embeddings,
    // FineTuning,
    // etc.
}

impl ApiDefinition for OpenAIApi {
    fn endpoint(&self) -> &'static str {
        match self {
            OpenAIApi::ChatCompletions => "/v1/chat/completions",
        }
    }

    fn from_endpoint(endpoint: &str) -> Option<Self> {
        match endpoint {
            "/v1/chat/completions" => Some(OpenAIApi::ChatCompletions),
            _ => None,
        }
    }

    fn supports_streaming(&self) -> bool {
        match self {
            OpenAIApi::ChatCompletions => true,
        }
    }

    fn supports_tools(&self) -> bool {
         match self {
            OpenAIApi::ChatCompletions => true,
        }
    }

    fn supports_vision(&self) -> bool {
        match self {
            OpenAIApi::ChatCompletions => true,
        }
    }

    fn all_variants() -> Vec<Self> {
        vec![
            OpenAIApi::ChatCompletions,
        ]
    }
}

/// Chat completions API request
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ChatCompletionsRequest {
    pub messages: Vec<Message>,
    pub model: String,
    // pub auduio: Option<Audio> // GOOD FIRST ISSUE: future support for audio input
    pub frequency_penalty: Option<f32>,
    // Function calling configuration has been deprecated, but we keep it for compatibility
    pub function_call: Option<FunctionChoice>,
    pub functions: Option<Vec<Tool>>,
    pub logit_bias: Option<HashMap<String, i32>>,
    pub logprobs: Option<bool>,
    pub max_completion_tokens: Option<u32>,
    // Maximum tokens in the response has been deprecated, but we keep it for compatibility
    pub max_tokens: Option<u32>,
    pub modalities: Option<Vec<String>>,
    pub metadata: Option<HashMap<String, String>>,
    pub n: Option<u32>,
    pub presence_penalty: Option<f32>,
    pub parallel_tool_calls: Option<bool>,
    pub prediction: Option<StaticContent>,
    // pub reasoning_effect: Option<bool>, // GOOD FIRST ISSUE: Future support for reasoning effects
    pub response_format: Option<Value>,
    // pub safety_identifier: Option<String>, // GOOD FIRST ISSUE: Future support for safety identifiers
    pub seed: Option<i32>,
    pub service_tier: Option<String>,
    pub stop: Option<Vec<String>>,
    pub store: Option<bool>,
    pub stream: Option<bool>,
    pub stream_options: Option<StreamOptions>,
    pub temperature: Option<f32>,
    pub tool_choice: Option<ToolChoice>,
    pub tools: Option<Vec<Tool>>,
    pub top_p: Option<f32>,
    pub top_logprobs: Option<u32>,
    pub user: Option<String>,
    // pub web_search: Option<bool>, // GOOD FIRST ISSUE: Future support for web search
}

// ============================================================================
// CHAT COMPLETIONS API TYPES
// ============================================================================

/// Message role in a chat conversation
#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum Role {
    System,
    User,
    Assistant,
    Tool,
}

#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct Message {
    pub role: Role,
    pub content: MessageContent,
    pub name: Option<String>,
    /// Tool calls made by the assistant (only present for assistant role)
    pub tool_calls: Option<Vec<ToolCall>>,
    /// ID of the tool call that this message is responding to (only present for tool role)
    pub tool_call_id: Option<String>,
}



#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ResponseMessage {
    pub role: Role,
    /// The contents of the message (can be null for some cases)
    pub content: Option<String>,
    /// The refusal message generated by the model
    pub refusal: Option<String>,
    /// Annotations for the message, when applicable, as when using the web search tool
    pub annotations: Option<Vec<Value>>,
    /// If the audio output modality is requested, this object contains data about the audio response
    pub audio: Option<Value>,
    /// Deprecated and replaced by tool_calls. The name and arguments of a function that should be called
    #[serde(skip_serializing_if = "Option::is_none")]
    pub function_call: Option<FunctionCall>,
    /// The tool calls generated by the model, such as function calls
    pub tool_calls: Option<Vec<ToolCall>>,
}

impl ResponseMessage {
    /// Convert ResponseMessage to Message for internal processing
    /// This is useful for transformations that need to work with the request Message type
    pub fn to_message(&self) -> Message {
        Message {
            role: self.role.clone(),
            content: self.content.as_ref()
                .map(|s| MessageContent::Text(s.clone()))
                .unwrap_or(MessageContent::Text(String::new())),
            name: None, // Response messages don't have names in the same way request messages do
            tool_calls: self.tool_calls.clone(),
            tool_call_id: None, // Response messages don't have tool_call_id
        }
    }
}

/// In the OpenAI API, this is represented as either:
/// - A string for simple text content
/// - An array of content parts for multimodal content (text + images)
#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(untagged)]
pub enum MessageContent {
    Text(String),
    Parts(Vec<ContentPart>),
}

/// Individual content part within a message (text or image)
#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(tag = "type")]
pub enum ContentPart {
    #[serde(rename = "text")]
    Text { text: String },
    #[serde(rename = "image_url")]
    ImageUrl { image_url: ImageUrl },
}

/// Image URL configuration for vision capabilities
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ImageUrl {
    pub url: String,
    pub detail: Option<String>,
}

/// A single message in a chat conversation


/// A tool call made by the assistant
#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub struct ToolCall {
    pub id: String,
    #[serde(rename = "type")]
    pub call_type: String,
    pub function: FunctionCall,
}

/// Function call within a tool call
#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub struct FunctionCall {
    pub name: String,
    pub arguments: String,
}

/// Tool definition for function calling
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct Tool {
    #[serde(rename = "type")]
    pub tool_type: String,
    pub function: Function,
}

/// Function definition within a tool
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct Function {
    pub name: String,
    pub description: Option<String>,
    pub parameters: Value,
    pub strict: Option<bool>,
}

/// Tool choice configuration
#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(untagged)]
pub enum ToolChoice {
    String(String), // "none", "auto", "required"
    Function {
        #[serde(rename = "type")]
        choice_type: String,
        function: FunctionChoice,
    },
}

/// Specific function choice
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct FunctionChoice {
    pub name: String,
}

/// Static content for prediction/prefill functionality
///
/// Static predicted output content, such as the content of a text file
/// that is being regenerated.
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct StaticContent {
    /// The type of the predicted content you want to provide.
    /// This type is currently always "content".
    #[serde(rename = "type")]
    pub content_type: String,
    /// The content that should be matched when generating a model response.
    /// If generated tokens would match this content, the entire model response
    /// can be returned much more quickly.
    ///
    /// Can be either:
    /// - A string for simple text content
    /// - An array of content parts for structured content
    pub content: StaticContentType,
}

/// Content type for static/predicted content
#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(untagged)]
pub enum StaticContentType {
    /// Simple text content - the content used for a Predicted Output.
    /// This is often the text of a file you are regenerating with minor changes.
    Text(String),
    /// An array of content parts with a defined type.
    /// Can contain text inputs and other supported content types.
    Parts(Vec<ContentPart>),
}


/// Chat completions API response
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ChatCompletionsResponse {
    pub id: String,
    pub object: String,
    pub created: u64,
    pub model: String,
    pub choices: Vec<Choice>,
    pub usage: Usage,
    pub system_fingerprint: Option<String>,
}

/// Finish reason for completion
#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, Eq)]
#[serde(rename_all = "snake_case")]
pub enum FinishReason {
    Stop,
    Length,
    ToolCalls,
    ContentFilter,
    FunctionCall, // Legacy
}

/// Token usage information
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct Usage {
    pub prompt_tokens: u32,
    pub completion_tokens: u32,
    pub total_tokens: u32,
    pub prompt_tokens_details: Option<PromptTokensDetails>,
    pub completion_tokens_details: Option<CompletionTokensDetails>,
}

/// Detailed breakdown of prompt tokens
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct PromptTokensDetails {
    pub cached_tokens: Option<u32>,
    pub audio_tokens: Option<u32>,
}

/// Detailed breakdown of completion tokens
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct CompletionTokensDetails {
    pub reasoning_tokens: Option<u32>,
    pub audio_tokens: Option<u32>,
    pub accepted_prediction_tokens: Option<u32>,
    pub rejected_prediction_tokens: Option<u32>,
}

/// A single choice in the response
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct Choice {
    pub index: u32,
    pub message: ResponseMessage,
    pub finish_reason: Option<FinishReason>,
    pub logprobs: Option<Value>,
}


// ============================================================================
// STREAMING API TYPES
// ============================================================================

/// Streaming response from chat completions API
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ChatCompletionsStreamResponse {
    pub id: String,
    pub object: String,
    pub created: u64,
    pub model: String,
    pub choices: Vec<StreamChoice>,
    pub usage: Option<Usage>, // Only in final chunk
    pub system_fingerprint: Option<String>,
    /// Specifies the processing type used for serving the request
    pub service_tier: Option<String>,
}


/// A choice in a streaming response
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct StreamChoice {
    pub index: u32,
    pub delta: MessageDelta,
    pub finish_reason: Option<FinishReason>,
    pub logprobs: Option<Value>,
}

/// Message delta for streaming updates
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct MessageDelta {
    pub role: Option<Role>,
    pub content: Option<String>,
    /// The refusal message generated by the model
    pub refusal: Option<String>,
    /// Deprecated and replaced by tool_calls. The name and arguments of a function that should be called
    pub function_call: Option<FunctionCall>,
    pub tool_calls: Option<Vec<ToolCallDelta>>,
}

/// Tool call delta for streaming tool call updates
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ToolCallDelta {
    pub index: u32,
    pub id: Option<String>,
    #[serde(rename = "type")]
    pub call_type: Option<String>,
    pub function: Option<FunctionCallDelta>,
}

/// Function call delta for streaming function call updates
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct FunctionCallDelta {
    pub name: Option<String>,
    pub arguments: Option<String>,
}


// ============================================================================
// LEGACY COMPATIBILITY & TYPE ALIASES
// ============================================================================

/// Stream options for controlling streaming behavior
#[skip_serializing_none]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct StreamOptions {
    pub include_usage: Option<bool>,
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;
    use std::collections::HashMap;

    #[test]
    fn test_required_fields() {
        // Test ChatCompletionsRequest with only required fields
        let minimal_request = ChatCompletionsRequest {
            model: "gpt-4".to_string(),
            messages: vec![Message {
                role: Role::User,
                content: MessageContent::Text("Hello, world!".to_string()),
                name: None,
                tool_calls: None,
                tool_call_id: None,
            }],
            // All other fields are optional
            frequency_penalty: None,
            function_call: None,
            functions: None,
            logit_bias: None,
            logprobs: None,
            max_completion_tokens: None,
            max_tokens: None,
            modalities: None,
            metadata: None,
            n: None,
            presence_penalty: None,
            parallel_tool_calls: None,
            prediction: None,
            response_format: None,
            seed: None,
            service_tier: None,
            stop: None,
            store: None,
            stream: None,
            stream_options: None,
            temperature: None,
            tool_choice: None,
            tools: None,
            top_p: None,
            top_logprobs: None,
            user: None,
        };

        // Test serialization of minimal request
        let json = serde_json::to_value(&minimal_request).unwrap();
        let obj = json.as_object().unwrap();

        // Required fields should be present
        assert_eq!(obj["model"], "gpt-4");
        assert!(obj.contains_key("messages"));
        assert_eq!(obj["messages"].as_array().unwrap().len(), 1);

        // Test message structure
        let message = &obj["messages"].as_array().unwrap()[0];
        assert_eq!(message["role"], "user");
        assert_eq!(message["content"], "Hello, world!");

        // Optional fields should not be present
        assert!(!obj.contains_key("temperature"));
        assert!(!obj.contains_key("max_tokens"));
        assert!(!obj.contains_key("stream"));
    }

    #[test]
    fn test_optional_fields_serialization() {
        // Test that optional fields work correctly and None fields are skipped
        let request_with_options = ChatCompletionsRequest {
            model: "gpt-4".to_string(),
            messages: vec![Message {
                role: Role::User,
                content: MessageContent::Text("Test message".to_string()),
                name: Some("test_user".to_string()), // Optional field with value
                tool_calls: None, // Optional field as None
                tool_call_id: None,
            }],
            temperature: Some(0.7),
            max_tokens: Some(150),
            stream: Some(true),
            stream_options: Some(StreamOptions {
                include_usage: Some(true),
            }),
            metadata: Some(HashMap::from([
                ("user_id".to_string(), "123".to_string()),
            ])),
            // These should be None and skipped
            top_p: None,
            frequency_penalty: None,
            presence_penalty: None,
            stop: None,
            tools: None,
            tool_choice: None,
            parallel_tool_calls: None,
            user: None,
            logit_bias: None,
            logprobs: None,
            max_completion_tokens: None,
            modalities: None,
            n: None,
            prediction: None,
            response_format: None,
            seed: None,
            service_tier: None,
            store: None,
            top_logprobs: None,
            function_call: None,
            functions: None,
        };

        let json = serde_json::to_value(&request_with_options).unwrap();
        let obj = json.as_object().unwrap();

        // Fields with Some values should be present
        assert!((obj["temperature"].as_f64().unwrap() - 0.7).abs() < 1e-6);
        assert_eq!(obj["max_tokens"], 150);
        assert_eq!(obj["stream"], true);
        assert!(obj.contains_key("stream_options"));
        assert!(obj.contains_key("metadata"));

        // Message name should be present
        let message = &obj["messages"].as_array().unwrap()[0];
        assert_eq!(message["name"], "test_user");
        assert!(!message.as_object().unwrap().contains_key("tool_calls"));

        // None fields should be skipped
        assert!(!obj.contains_key("top_p"));
        assert!(!obj.contains_key("frequency_penalty"));
        assert!(!obj.contains_key("presence_penalty"));
        assert!(!obj.contains_key("stop"));
        assert!(!obj.contains_key("tools"));
    }

    #[test]
    fn test_nested_types_serialization() {
        // Test tools, message parts, static content, and streaming deltas

        // Test tool serialization
        let tool = Tool {
            tool_type: "function".to_string(),
            function: Function {
                name: "get_weather".to_string(),
                description: Some("Get weather information".to_string()),
                parameters: json!({
                    "type": "object",
                    "properties": {
                        "location": {"type": "string"}
                    }
                }),
                strict: Some(true),
            },
        };

        let tool_json = serde_json::to_value(&tool).unwrap();
        assert_eq!(tool_json["type"], "function");
        assert_eq!(tool_json["function"]["name"], "get_weather");
        assert!(tool_json["function"].as_object().unwrap().contains_key("description"));
        assert_eq!(tool_json["function"]["strict"], true);

        // Test multimodal message content
        let multimodal_message = Message {
            role: Role::User,
            content: MessageContent::Parts(vec![
                ContentPart::Text {
                    text: "What's in this image?".to_string(),
                },
                ContentPart::ImageUrl {
                    image_url: ImageUrl {
                        url: "https://example.com/image.jpg".to_string(),
                        detail: Some("high".to_string()),
                    },
                },
            ]),
            name: None,
            tool_calls: None,
            tool_call_id: None,
        };

        let multimodal_json = serde_json::to_value(&multimodal_message).unwrap();
        let content_array = multimodal_json["content"].as_array().unwrap();
        assert_eq!(content_array.len(), 2);
        assert_eq!(content_array[0]["type"], "text");
        assert_eq!(content_array[1]["type"], "image_url");
        assert_eq!(content_array[1]["image_url"]["detail"], "high");

        // Test static content for prediction
        let static_content = StaticContent {
            content_type: "content".to_string(),
            content: StaticContentType::Text("Predicted output".to_string()),
        };

        let static_json = serde_json::to_value(&static_content).unwrap();
        assert_eq!(static_json["type"], "content");
        assert_eq!(static_json["content"], "Predicted output");

        // Test streaming delta
        let stream_delta = MessageDelta {
            role: Some(Role::Assistant),
            content: Some("Streaming response".to_string()),
            refusal: None,
            function_call: None,
            tool_calls: Some(vec![ToolCallDelta {
                index: 0,
                id: Some("call_123".to_string()),
                call_type: Some("function".to_string()),
                function: Some(FunctionCallDelta {
                    name: Some("get_weather".to_string()),
                    arguments: Some(r#"{"location":"NYC"}"#.to_string()),
                }),
            }]),
        };

        let delta_json = serde_json::to_value(&stream_delta).unwrap();
        assert_eq!(delta_json["role"], "assistant");
        assert_eq!(delta_json["content"], "Streaming response");
        assert!(delta_json["tool_calls"].as_array().unwrap().len() == 1);
        assert!(!delta_json.as_object().unwrap().contains_key("refusal")); // None should be skipped
    }

    #[test]
    fn test_api_provider_trait() {
        // Test the ApiDefinition trait implementation
        let api = OpenAIApi::ChatCompletions;

        // Test trait methods
        assert_eq!(api.endpoint(), "/v1/chat/completions");
        assert!(api.supports_streaming());
        assert!(api.supports_tools());
        assert!(api.supports_vision());

        // Test from_endpoint
        let found_api = OpenAIApi::from_endpoint("/v1/chat/completions");
        assert_eq!(found_api, Some(OpenAIApi::ChatCompletions));

        let not_found = OpenAIApi::from_endpoint("/v1/unknown");
        assert_eq!(not_found, None);

        // Test all_variants
        let all_variants = OpenAIApi::all_variants();
        assert_eq!(all_variants.len(), 1);
        assert_eq!(all_variants[0], OpenAIApi::ChatCompletions);
    }

    #[test]
    fn test_role_specific_behavior() {
        // Test role-specific serialization behavior

        // User message - basic content, no tool-related fields
        let user_message = Message {
            role: Role::User,
            content: MessageContent::Text("Hello!".to_string()),
            name: Some("user123".to_string()),
            tool_calls: None,
            tool_call_id: None,
        };

        let user_json = serde_json::to_value(&user_message).unwrap();
        let user_obj = user_json.as_object().unwrap();
        assert_eq!(user_obj["role"], "user");
        assert_eq!(user_obj["name"], "user123");
        assert!(!user_obj.contains_key("tool_calls"));
        assert!(!user_obj.contains_key("tool_call_id"));

        // Assistant message with tool calls
        let assistant_message = Message {
            role: Role::Assistant,
            content: MessageContent::Text("I'll help with that.".to_string()),
            name: None,
            tool_calls: Some(vec![ToolCall {
                id: "call_456".to_string(),
                call_type: "function".to_string(),
                function: FunctionCall {
                    name: "get_weather".to_string(),
                    arguments: r#"{"location":"SF"}"#.to_string(),
                },
            }]),
            tool_call_id: None, // Should not be present for assistant
        };

        let assistant_json = serde_json::to_value(&assistant_message).unwrap();
        let assistant_obj = assistant_json.as_object().unwrap();
        assert_eq!(assistant_obj["role"], "assistant");
        assert!(assistant_obj.contains_key("tool_calls"));
        assert!(!assistant_obj.contains_key("tool_call_id")); // Not for assistant
        assert!(!assistant_obj.contains_key("name")); // None, so skipped

        // Tool message responding to a call
        let tool_message = Message {
            role: Role::Tool,
            content: MessageContent::Text("Weather is sunny".to_string()),
            name: None,
            tool_calls: None, // Should not be present for tool messages
            tool_call_id: Some("call_456".to_string()),
        };

        let tool_json = serde_json::to_value(&tool_message).unwrap();
        let tool_obj = tool_json.as_object().unwrap();
        assert_eq!(tool_obj["role"], "tool");
        assert_eq!(tool_obj["tool_call_id"], "call_456");
        assert!(!tool_obj.contains_key("tool_calls")); // Not for tool messages

        // Test ResponseMessage vs Message differences
        let response_message = ResponseMessage {
            role: Role::Assistant,
            content: Some("Response content".to_string()),
            refusal: None,
            annotations: Some(vec![json!({"type": "citation"})]),
            audio: None,
            function_call: None,
            tool_calls: None,
        };

        let response_json = serde_json::to_value(&response_message).unwrap();
        let response_obj = response_json.as_object().unwrap();

        // ResponseMessage has different fields than Message
        assert!(response_obj.contains_key("annotations"));
        assert!(!response_obj.contains_key("name")); // Not in ResponseMessage
        assert!(!response_obj.contains_key("tool_call_id")); // Not in ResponseMessage

        // Test conversion
        let converted = response_message.to_message();
        assert_eq!(converted.role, Role::Assistant);
        if let MessageContent::Text(text) = converted.content {
            assert_eq!(text, "Response content");
        } else {
            panic!("Expected text content");
        }
    }
}
